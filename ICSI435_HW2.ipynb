{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KentaLange/ICSI435HW2/blob/main/ICSI435_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfD22a-uyaxF",
    "outputId": "c0c83896-44b9-4de9-fbd1-422b318aa5cb"
   },
   "outputs": [],
   "source": [
    "!ls -l /content/ANN.py\n",
    "!pwd\n",
    "!ls -l /content/ColabTest/mlhw2/ANN_LeNet_MNIST_demo.py\n",
    "! curl -O http://yann.lecun.com/exdb/mnist/\n",
    "#!python gdrive/My\\ Drive/Colab\\ Notebooks/object_detection_demo-master/test.py\n",
    "#download_mnist()\n",
    "#save_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SARJsxIc9TAn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import seaborn as sns\n",
    "import socket\n",
    "import sys\n",
    "import argparse\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "#import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "sys.path.append(\"../ColabTest/mlhw2\")\n",
    "\n",
    "import MNIST_util\n",
    "import nn_layer\n",
    "import ANN\n",
    "import CNN\n",
    "import activation\n",
    "import pooling\n",
    "import nn_layer\n",
    "import conv_layer\n",
    "\n",
    "import loss\n",
    "import optimizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, losses, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ANN import TwoLayerNet\n",
    "class ThreeLayerNet ():\n",
    "  def __init__(self, D_in, H1, H2, D_out, weights=''):\n",
    "    #The H2 in  __init__ function is the output dimension of the second FC layer and the input dimension of the third FC layer.\n",
    "\n",
    "    self.FC1 = nn_layer.FC (D_in, H1)#28*28\n",
    "    self.ReLU1 = activation.ReLU()\n",
    "    self.FC2 = nn_layer.FC (H1, H2)\n",
    "    self.ReLU2 = activation.ReLU()\n",
    "    self.FC3 = nn_layer.FC(H2, D_out)#10*10\n",
    "    if weights == '':\n",
    "      pass\n",
    "    else:\n",
    "      # Load weights from file\n",
    "      with open (weights,'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "        self.set_params(params)\n",
    "\n",
    "\n",
    "  def forward (self, X):\n",
    "    h1 = self.FC1._forward(X)\n",
    "    a1 = self.ReLU1._forward(h1)\n",
    "    h2 = self.FC2._forward(a1)\n",
    "    a2 = self.ReLU2._forward(h2)\n",
    "    h3 = self.FC3._forward(a2)\n",
    "    return h3\n",
    "\n",
    "  def backward (self, dout):\n",
    "    dout = self.FC3._backward(dout)\n",
    "    dout = self.ReLU2._backward(dout)\n",
    "    dout = self.FC2._backward(dout)\n",
    "    dout = self.ReLU1._backward(dout)\n",
    "    dout = self.FC1._backward(dout)\n",
    "\n",
    "\n",
    "\n",
    "  def get_params(self):\n",
    "    return [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b,self.FC3.W,self.FC3.b]\n",
    "\n",
    "\n",
    "  def set_params(self, params):\n",
    "    [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b,self.FC3.W,self.FC3.b] = params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4MtYfJfY_bG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ========== Net Trainer - Begin ==========\n",
    "\n",
    "def get_batch (X, Y, batch_size):\n",
    "# randomly select batch_size data samples\n",
    "  N = len(X)\n",
    "  i = random.randint(1, N-batch_size)\n",
    "  return X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "def MakeOneHot (Y, D_out):\n",
    "  N = Y.shape[0]\n",
    "  Z = np.zeros((N, D_out))\n",
    "  Z[np.arange(N), Y] = 1\n",
    "  return Z\n",
    "\n",
    "class MNIST_Trainer ():\n",
    "  def __init__(self, X_train, Y_train, Net='LeNet5', opti='SGDMomentum'):\n",
    "    # Prepare Data: Load, Shuffle, Normalization, Batching, Preprocessing\n",
    "    self.X_train = X_train\n",
    "    self.Y_train = Y_train\n",
    "\n",
    "    self.batch_size = 64\n",
    "    # D_in: input depth of network, 784, 28*28 input grayscale image\n",
    "    self.D_in = 784\n",
    "    # D_out: output depth of network = 10, the 10 digits\n",
    "    self.D_out = 10\n",
    "\n",
    "    print ('  Net: ' + str(Net))\n",
    "    print ('  batch_size: ' + str(self.batch_size))\n",
    "    print ('  D_in: ' + str(self.D_in))\n",
    "    print ('  D_out: ' + str(self.D_out))\n",
    "    print ('  Optimizer: ' + opti)\n",
    "\n",
    "    # =======================\n",
    "    if Net == 'TwoLayerNet':\n",
    "      # H is the size of the one hidden layer.\n",
    "      H=400\n",
    "      self.model = ANN.TwoLayerNet (self.D_in, H, self.D_out)\n",
    "    elif Net == 'ThreeLayerNet':\n",
    "    #######################################\n",
    "    ############  TODO   ##################\n",
    "    #######################################\n",
    "      # H1, H2 are the size of the two hidden layers.\n",
    "      #The H2 in  __init__ function is the output dimension of the second FC layer and the input dimension of the third FC layer.\n",
    "      H1=300\n",
    "      H2=100\n",
    "      self.model = ThreeLayerNet (self.D_in, H1, H2, self.D_out)\n",
    "\n",
    "    elif Net == 'LeNet5':\n",
    "      self.model = CNN.LeNet5 ()\n",
    "\n",
    "    # store training loss over iterations, for later visualization\n",
    "    self.losses = []\n",
    "\n",
    "    if opti == 'SGD':\n",
    "      self.opti = optimizer.SGD (self.model.get_params(), lr=0.0001, reg=0)\n",
    "    else:\n",
    "      self.opti = optimizer.SGDMomentum (self.model.get_params(), lr=0.0001, momentum=0.80, reg=0.00003)\n",
    "\n",
    "    self.criterion = loss.CrossEntropyLoss ()\n",
    "\n",
    "\n",
    "  def Train (self, Iter = None):\n",
    "    if not Iter:\n",
    "      Iter = 25000\n",
    "\n",
    "    for i in range(Iter):\n",
    "      # get batch, make onehot\n",
    "      X_batch, Y_batch = get_batch (self.X_train, self.Y_train, self.batch_size)\n",
    "      Y_batch = MakeOneHot (Y_batch, self.D_out)\n",
    "\n",
    "      # forward, loss, backward, step\n",
    "      Y_pred = self.model.forward (X_batch)\n",
    "      loss, dout = self.criterion.get (Y_pred, Y_batch)\n",
    "      self.model.backward (dout)\n",
    "      self.opti.step()\n",
    "\n",
    "      if i % 100 == 0:\n",
    "        print ('Iter %d (%.2f%%), loss = %f' % (i, 100.0*i/Iter, loss))\n",
    "        self.losses.append (loss)\n",
    "\n",
    "      #if i==0:\n",
    "      #  viz_batch (X_batch, i)\n",
    "\n",
    "    return self.model\n",
    "\n",
    "# ========== Net Trainer - End ==========\n",
    "\n",
    "# ========== Evaluation - Begin ==========\n",
    "\n",
    "def determine_Train_Acc (model, X_train, Y_train):\n",
    "  Y_pred = model.forward (X_train)\n",
    "  result = np.argmax (Y_pred, axis=1) - Y_train\n",
    "  result = list (result)\n",
    "\n",
    "  n_correct = result.count(0)\n",
    "  n_total = X_train.shape[0]\n",
    "  Acc = float(n_correct) / n_total\n",
    "  print ('TRAIN--> Correct: %d out of %d. Acc=%f' \\\n",
    "    % (n_correct, n_total, Acc))\n",
    "  return Acc\n",
    "\n",
    "def determine_Test_Acc (model, X_test, Y_test):\n",
    "  Y_pred = model.forward (X_test)\n",
    "  result = np.argmax (Y_pred, axis=1) - Y_test\n",
    "  result = list (result)\n",
    "\n",
    "  n_correct = result.count(0)\n",
    "  n_total = X_test.shape[0]\n",
    "  Acc = float(n_correct) / n_total\n",
    "  print ('TEST--> Correct: %d out of %d. Acc=%f' \\\n",
    "    % (n_correct, n_total, Acc))\n",
    "  return Acc\n",
    "\n",
    "# ========== Evaluation - End ==========\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIGgQJ43ZY9y"
   },
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    " # parser = argparse.ArgumentParser()\n",
    "  #parser.add_argument('-model', dest='model', default='TwoLayerNet', choices=['TwoLayerNet', 'ThreeLayerNet', 'LeNet5'], help=\"Select the NeuralNet model\")\n",
    "  #parser.add_argument('-iter', dest='iter', default=25000, type=int, help=\"Training iterations\")\n",
    "  #parser.add_argument('-opti', dest='opti', default='SGDMomentum', choices=['SGDMomentum', 'SGD'], help=\"Select optimizer\")\n",
    "  #args = parser.parse_args()\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = MNIST_util.MNIST_preparation ('../ColabTest/mlhw2/')\n",
    "Y_enc_train = MakeOneHot (Y_train, 10)\n",
    "Y_enc_test = MakeOneHot (Y_test, 10)\n",
    "print(f\"Initial  data shape: {X_train.shape} and {Y_train.shape}, {X_test.shape} and {Y_test.shape}, 1H {Y_enc_train.shape} and {Y_enc_test.shape} \")\n",
    "\n",
    "model = None\n",
    "X_val = X_train[-2000:,:,]\n",
    "Y_val = Y_enc_train[-2000:]\n",
    "\n",
    "print(f'Initial Val Shape: {X_val.shape} and {Y_val.shape}')\n",
    "\n",
    "X_train_data = X_train[:-2000,:,]\n",
    "Y_train_data = Y_enc_train[:-2000]\n",
    "\n",
    "def mainLoop (model_name,iteration,optimizer):\n",
    "  #Since I am not using terminal to run this, I made this as a method.\n",
    "  #X_train, Y_train, X_test, Y_test = MNIST_util.MNIST_preparation ()\n",
    "\n",
    "  # Net: TwoLayerNet, ThreeLayerNet, LeNet5\n",
    "    if model_name == 'LeNet5':\n",
    "        model = LeNet(iter,opti)\n",
    "        model.name = \"LeNet5\"\n",
    "    elif model_name == 'TwoLayerNet':\n",
    "        model = TwoLayerNet(iter,optimizer)\n",
    "        model.name = \"TwoLayerNet\"\n",
    "    elif model_name == 'ThreeLayerNet':\n",
    "        model = ThreeLayerNet(iter,optimizer)\n",
    "        model.name = \"ThreeLayerNet\"\n",
    "    print(model.summary())\n",
    "    #optim: SGD, SGDMomentum\n",
    "    #opti = optimizer\n",
    "    #trainer = MNIST_Trainer (X_train, Y_train, Net, opti)\n",
    "\n",
    "    if optimizer == 'SGD':\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    elif optimizer == 'SGDMomentum':\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(momentum=.8, learning_rate=0.0001), loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam, loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "  #For 25000 iter TwoLayerNet, we should get train Acc 0.937983, test Acc 0.938700\n",
    "  #For 25000 iter ThreeLayerNet, we should get train Acc 0.953133, test Acc 0.952500\n",
    "  #For 1000 iter LeNet5, we should get test Acc 0.1135\n",
    "  #Iter = iteration\n",
    "  #model = trainer.Train (Iter)\n",
    "\n",
    "    history = model.fit(X_train_data, Y_train_data, batch_size=64, epochs=iteration, validation_data=(X_val, Y_val)  )\n",
    "    # weights = model.get_params()\n",
    "    # with open ('~weights.pkl','wb') as f:\n",
    "    #   pickle.dump (weights, f)\n",
    "\n",
    "    #genGraph(history['loss'], model_name)\n",
    "    model.evaluate(X_test,Y_enc_test)\n",
    "    return history,model\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "  # save params\n",
    "\n",
    "  #######################################\n",
    "  ############  TODO   ##################\n",
    "  #######################################\n",
    "\n",
    "  # plot training l\n",
    "  #y=training loss-self.losses from trainer.losses\n",
    "  #x=iteration number\n",
    "\n",
    "#  determine_Train_Acc (model, X_train, Y_train)\n",
    "#  determine_Test_Acc (model, X_test, Y_test)\n",
    "#  return trainer,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet(iter:int=0,opti:str=''):\n",
    "    # img_shape = (1, 28, 28)\n",
    "    # X_train = X_train.reshape(-1, *img_shape)\n",
    "    # X_test = X_test.reshape(-1, *img_shape)\n",
    "    # Pad two to the right, two down from 0... \n",
    "    ## Commented out /255 as this is done elsewhere normalize values to 1 (I guess)\n",
    "\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=X_train.shape[1:]))\n",
    "    model.add(layers.AveragePooling2D(2))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    model.add(layers.Conv2D(16, 5, activation='tanh'))\n",
    "    model.add(layers.AveragePooling2D(2))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    model.add(layers.Conv2D(120, 5, activation='tanh'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(84, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def TwoLayerNet(iter:int=0,opti:str=''):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=(784,)))\n",
    "#    model.add(layers.Flatten(input_shape=(0,784)))\n",
    "    model.add(layers.Dense(400, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def ThreeLayerNet(iter:int=0,opti:str=''):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(shape=(784,)))\n",
    " #   model.add(layers.Flatten(input_shape=(784)))\n",
    "    model.add(layers.Dense(300, activation='relu'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes losses and title of the graph. X-axis represents the number of iteration/100. Y-axis represents the losses.\n",
    "def genGraph(losses,title=''):\n",
    "  plt.figure()\n",
    "  plt.plot(losses)\n",
    "  plt.title(f'{title}: losses vs iteration')\n",
    "  plt.xlabel(\"Iterations\")\n",
    "  plt.ylabel(\"Losses\")\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvaVeEDnQkFG",
    "outputId": "15f6c3a3-c333-4a25-8913-985c705f4854"
   },
   "outputs": [],
   "source": [
    "#part (a):For 25000 iter TwoLayerNet, we should get train Acc 0.937983, test Acc 0.938700\n",
    "history,model=mainLoop(model_name='TwoLayerNet',iteration=250,optimizer='SGD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SmbzYLnhNr7"
   },
   "outputs": [],
   "source": [
    "genGraph(history.history['loss'], 'TwoLayerNet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "3IH08le6hOG-",
    "outputId": "55eacbf5-5575-447d-e163-ab0a6012d11c"
   },
   "outputs": [],
   "source": [
    "genGraph(trainer.losses,'part(a)-Two Layer SGD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q23DO3nXc4z8",
    "outputId": "f911f425-df2e-441c-9988-ddc304555854"
   },
   "outputs": [],
   "source": [
    "model=mainLoop(model_name='TwoLayerNet',iteration=250,optimizer='SGDMomentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baQyn8o2LBX-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "nm_aILeQlmq0",
    "outputId": "792b983f-a179-448c-a9b5-9e5d613ee90b"
   },
   "outputs": [],
   "source": [
    "genGraph(trainer.losses,'part(a)-Two Layer SGD-momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxRF3XZGc7D7",
    "outputId": "78839d02-96bb-4342-ba42-b47a20d78dbf"
   },
   "outputs": [],
   "source": [
    "#part (b):ThreeLayerNet by yourself. Set H1=300, H2=100, and train the ThreeLayerNet model 25000 iterations.\n",
    "trainer,model=mainLoop(model='ThreeLayerNet',iteration=25000,optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "cOwfvy0emhM1",
    "outputId": "71aa18ef-4f23-449f-b663-b976ad4dd32b"
   },
   "outputs": [],
   "source": [
    "#part(b)\n",
    "genGraph(trainer.losses,'part(b)-Three Layer SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZv3M4kGc7bG",
    "outputId": "fc020cdd-eea8-4fe9-964f-5f5c7def11b1"
   },
   "outputs": [],
   "source": [
    "trainer,model=mainLoop(model='ThreeLayerNet',iteration=25000,optimizer='SGDMomentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "2Yhpbx-um6Nu",
    "outputId": "c496c0a6-498f-4589-c8e3-5c2b2773db72"
   },
   "outputs": [],
   "source": [
    "genGraph(trainer.losses,'part(b)-Three Layer SGD-momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pR4fAjVAc7qL",
    "outputId": "401b8a9d-512d-44f1-9c24-99076288c8a4"
   },
   "outputs": [],
   "source": [
    "#part (c):Train LeNet5 model 2000 iterations, report the accuracy on testing dataset.\n",
    "#LeNet5 takes more than one hour to run. Needs good hardware to run.\n",
    "trainer,model=mainLoop(model='LeNet5',iteration=2000,optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "tEMOdjSEm-NZ",
    "outputId": "ea729f03-8f31-41ce-fe42-e5d2f6c2cda0"
   },
   "outputs": [],
   "source": [
    "genGraph(trainer.losses,'part(c)-Three Layer SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-b78ysQ-c7xB",
    "outputId": "305799bf-9727-460e-a99b-a99cee3db708"
   },
   "outputs": [],
   "source": [
    "#part(c): Session crashs after using all available RAM.\n",
    "mainLoop(model='LeNet5',iteration=2000,optimizer='SGDMomentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb_1iaxca01c"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "I2CA9Z5UW1n_",
    "outputId": "c5fad710-b246-4540-f251-48fdc1bed449"
   },
   "outputs": [],
   "source": [
    "genGraph(trainer.losses,'part(c)-Three Layer SGD-Momentum')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyOyxAwTc+EK0A2lbwRqmQTd",
   "gpuType": "V28",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
